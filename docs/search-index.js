znaiSearchData = [["@@index@@liftwizard","","","Liftwizard","Liftwizard is a collection of bundles and add-ons for https://www.dropwizard.io/ Dropwizard, the Java framework for writing web services.There are very few dependencies between the bundles, so you can pick and choose the ones you want. Module groups The bundles can be loosely grouped into categories.Dropwizard configuration JSON serialization/deserialization Servlet client/server logging GraphQL utility https://github.com/goldmansachs/reladomo Reladomo ORM integration for Dropwizard Other Dropwizard utility Guide structure In this guide, we'll start with the application https://github.com/dropwizard/dropwizard/tree/master/dropwizard-example dropwizard-example which is a maven module that's part of the main Dropwizard repository. We'll gradually turn it into https://github.com/motlin/liftwizard/tree/master/liftwizard-example liftwizard-example , an application with an identical service api that uses as many Liftwizard features as possible."],["introduction@@liftwizard@@","Introduction","Liftwizard","","Liftwizard is a collection of bundles and add-ons for https://www.dropwizard.io/ Dropwizard, the Java framework for writing web services.There are very few dependencies between the bundles, so you can pick and choose the ones you want.The bundles can be loosely grouped into categories:Dropwizard configuration and bundles Jackson JSON serialization/deserialization Servlet client/server logging https://github.com/goldmansachs/reladomo Reladomo ORM integration for Dropwizard JUnit 4 and JUnit 5 test utilities"],["configuration@@environment-variable-substitution@@in-example-applications","Configuration","Environment Variable Substitution","in example applications","The EnvironmentConfigBundle supports environment variable substitution inside Dropwizard configuration files.In the example applications, environment variable substitution is used for defaultName . yaml template: Hello, %s! defaultName: ${DW_DEFAULT_NAME:-Stranger} We can see this in action by running the render command, with and without the environment variable set. bash $ java -jar target/liftwizard-example-0.1.0.jar render example.yml --include-default INFO [2020-05-02 03:07:41,910] com.example.helloworld.cli.RenderCommand: DEFAULT => Hello, Stranger! $ DW_DEFAULT_NAME=EnvSubstitution java -jar target/liftwizard-example-0.1.0.jar render example.yml --include-default INFO [2020-05-02 03:08:05,685] com.example.helloworld.cli.RenderCommand: DEFAULT => Hello, EnvSubstitution!"],["configuration@@environment-variable-substitution@@in-dropwizard-example","Configuration","Environment Variable Substitution","in dropwizard-example","java @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { // Enable variable substitution with environment variables bootstrap.setConfigurationSourceProvider( new SubstitutingSourceProvider( bootstrap.getConfigurationSourceProvider(), new EnvironmentVariableSubstitutor(false) ) ); // ... }"],["configuration@@environment-variable-substitution@@in-liftwizard-example","Configuration","Environment Variable Substitution","in liftwizard-example","java @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { bootstrap.addBundle(new EnvironmentConfigBundle()); // ... } EnvironmentConfigBundle lives in the liftwizard-bundle-environment-config module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-bundle-environment-config</artifactId> </dependency>"],["configuration@@json5-configuration@@configuration-through-json5-instead-of-yaml","Configuration","Json5 Configuration","Configuration through json5 instead of yaml","Dropwizard's configuration is specified in yaml by default. While yaml has nice properties, you may prefer json or some other format.Dropwizard's https://www.dropwizard.io/en/latest/manual/core.html#configuration documentation claims:If your configuration file doesn't end in .yml or .yaml, Dropwizard tries to parse it as a JSON file.This is easily disproved by renaming example.yml to example.json and trying to run the application. It will incorrectly start without error.Since json syntax is a subset of yml syntax, you can go ahead and convert your configuration file to json without changing the file extension from yaml or yml. However, this approach doesn't prevent you from accidentally using yaml syntax.You can change your application to use json for its configuration using JsonConfigurationFactoryFactory . java @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { bootstrap.setConfigurationFactoryFactory(new JsonConfigurationFactoryFactory<>()); // ... } JsonConfigurationFactoryFactory uses json5 syntax by default, using optional features in Jackson. So you'll still be able to include comments inside your configuration files.After adding the bundle, you'll have to convert your configuration files to json5 and rename them. So example.yml becomes example.json5 . Configuration files used in DropwizardAppRule / DropwizardAppExtension tests must be converted as well. So src/test/resources/test-example.yml becomes src/test/resources/test-example.json5"],["configuration@@json5-configuration@@adding-the-dependency","Configuration","Json5 Configuration","Adding the dependency","JsonConfigurationFactoryFactory lives in the liftwizard-configuration-factory-json module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-configuration-factory-json</artifactId> </dependency>"],["configuration@@ConfigLoggingBundle@@adding-the-dependency","Configuration","ConfigLoggingBundle","Adding the dependency","The ConfigLoggingBundle logs the Dropwizard configuration using SLF4J. It serializes the in-memory configuration object to json and logs that json, not the contents of the original configuration file. The output contains default values set by constructors, that were not specified in the original configuration file.To turn it on, add ConfigLoggingBundle to the list of registered bundles. @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { bootstrap.setConfigurationFactoryFactory(new JsonConfigurationFactoryFactory<>()); bootstrap.addBundle(new EnvironmentConfigBundle()); bootstrap.addBundle(new ObjectMapperBundle()); bootstrap.addBundle(new ConfigLoggingBundle()); StructuredArgumentsMDCLogger structuredLogger = new StructuredArgumentsMDCLogger(bootstrap.getObjectMapper()); bootstrap.addBundle(new JerseyHttpLoggingBundle(structuredLogger)); bootstrap.addBundle(new ClockBundle()); bootstrap.addBundle(new UUIDBundle()); bootstrap.addBundle(new H2Bundle()); bootstrap.addBundle(new ConnectionManagerHolderBundle()); bootstrap.addBundle(new ReladomoBundle()); bootstrap.addCommand(new RenderCommand()); bootstrap.addBundle(new AssetsBundle()); bootstrap.addBundle(new MigrationsBundle<>() { @Override public DataSourceFactory getDataSourceFactory(HelloWorldConfiguration configuration) { return configuration.getNamedDataSourcesFactory().getNamedDataSourceFactoryByName(\"h2-tcp\"); } }); bootstrap.addBundle(new LiftwizardLiquibaseMigrationBundle()); bootstrap.addBundle(new ViewBundle<>() { @Override public Map<String, Map<String, String>> getViewConfiguration(HelloWorldConfiguration configuration) { return configuration.getViewRendererConfiguration(); } }); bootstrap.addBundle(new Slf4jUncaughtExceptionHandlerBundle()); } Now HelloWorldApplication will log something like this on startup: INFO 12:53:29 [main] {liftwizard.priority=-8, liftwizard.bundle=ConfigLoggingBundle} io.liftwizard.dropwizard.bundle.config.logging.ConfigLoggingBundle: Inferred Dropwizard configuration: json5 { \"template\": \"Hello, %s!\", \"defaultName\": \"Stranger\", \"configLogging\": { \"enabled\": true }, // ... \"metrics\": { \"frequency\": \"1 minute\", \"reporters\": [ ] } } Note that the metrics section at the end was not specified in test-example.json5 . It comes from serializing the output of io.dropwizard.Configuration.getMetricsFactory() . @JsonProperty(\"metrics\") public MetricsFactory getMetricsFactory() { return metrics; } This output can be helpful for fleshing out the configuration file with default options. Including \"redundant\" defaults makes it easier to edit the configuration by hand. It's easier to flip a boolean flag from false to true than to first figure out where in the configuration file it belongs and the exact spelling of its key.The ConfigLoggingBundle also logs the \"default\" configuration at the DEBUG level. It does this by instantiating a new copy of the configuration class using the default no-arg constructor, serializing it to json, and logging it. The default configuration output can be useful for finding redundant configuration to remove. ConfigLoggingBundle lives in the liftwizard-bundle-logging-config module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-bundle-logging-config</artifactId> </dependency>"],["jackson@@ObjectMapperBundle@@adding-the-dependency","Jackson","ObjectMapperBundle","Adding the dependency","The ObjectMapperBundle configures the Jackson ObjectMapper used by Dropwizard for serializing and deserializing all responses, as well as for logging by bundles such as liftwizard-bundle-logging-config . ObjectMapperBundle supports configuring pretty-printing on or off, and serialization inclusion to any value in Jackson's JsonInclude.Include . ObjectMapperBundle also turns on all json5 features, turns on FAIL_ON_UNKNOWN_PROPERTIES , turns on STRICT_DUPLICATE_DETECTION , and turns on serialization of dates and Strings.To turn it on, add ObjectMapperBundle to the list of registered bundles. java @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { // JsonConfigurationFactoryFactory uses a separate ObjectMapper, and can be configured earlier bootstrap.setConfigurationFactoryFactory(new JsonConfigurationFactoryFactory<>()); bootstrap.addBundle(new EnvironmentConfigBundle()); bootstrap.addBundle(new ObjectMapperBundle()); // ConfigLoggingBundle uses the ObjectMapper configured by ObjectMapperBundle bootstrap.addBundle(new ConfigLoggingBundle()); // ... } You'll be able to see that ObjectMapperBundle is working because the output of ConfigLoggingBundle will now be pretty-printed by default. ObjectMapperBundle lives in the liftwizard-bundle-object-mapper module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-bundle-object-mapper</artifactId> </dependency>"],["logging@@JerseyHttpLoggingBundle@@","Logging","JerseyHttpLoggingBundle","","The JerseyHttpLoggingBundle is an alternative to Jersey's LoggingFeature . Jersey's LoggingFeature can be configured to log or not log bodies, but it cannot be configured to exclude headers. Since headers can include authentication tokens, you may not want to log headers, or only log those in an allow-list.The bundle can be configured:include/exclude request bodies include/exclude response bodies allow-list of headers include/exclude the list of excluded header names the max body size before truncation Through code, the bundle can be configured to log using different combinations of slf4j/log4j/logback with context in MDC or OpenTracing or a Map.To turn it on, add JerseyHttpLoggingBundle to the list of registered bundles. java @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { bootstrap.setConfigurationFactoryFactory(new JsonConfigurationFactoryFactory<>()); bootstrap.addBundle(new EnvironmentConfigBundle()); bootstrap.addBundle(new ObjectMapperBundle()); bootstrap.addBundle(new ConfigLoggingBundle()); StructuredArgumentsMDCLogger structuredLogger = new StructuredArgumentsMDCLogger(bootstrap.getObjectMapper()); bootstrap.addBundle(new JerseyHttpLoggingBundle(structuredLogger)); // ... } The bundle registers filters which gather all the arguments to log. A \"logger\" is passed into the constructor which abstracts over whether the logging uses logback or log4j, whether the structured arguments are converted into MDC, Markers, or a Map. The StructuredArgumentsMDCLogger in the example above logs using slf4j with context in MDC. java var mdcLogger = new StructuredArgumentsMDCLogger(bootstrap.getObjectMapper()); var logstashLogger = new StructuredArgumentsLogstashEncoderLogger(); Consumer<StructuredArguments> structuredLogger = structuredArguments -> { mdcLogger.accept(structuredArguments); logstashLogger.accept(structuredArguments); }; bootstrap.addBundle(new JerseyHttpLoggingBundle(structuredLogger)); JerseyHttpLoggingBundle lives in the liftwizard-bundle-logging-http module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-bundle-logging-http</artifactId> </dependency> In order to see the logging in action, we'll need to configure a log format that includes mdc and markers. test-example.json5 src/test/resources/test-example.json5 json5 { \"type\": \"console\", \"timeZone\": \"${LOGGING_TIMEZONE:-system}\", \"logFormat\": \"%highlight(%-5level) %cyan(%date{HH:mm:ss.SSS, %dwTimeZone}) %gray(\\\\(%file:%line\\\\)) [%white(%thread)] %blue(%marker) {%magenta(%mdc)} %green(%logger): %message%n%rootException\", \"includeCallerData\": true, } Next, lets turn on all the basic filters and see how they change what gets logged. Logging output We can rerun IntegrationTest and see the new logs in action. console DEBUG 13:21:49 [dw-249] io.liftwizard.servlet.logging.mdc.StructuredArgumentsMDCLogger: Response sent <> < response.http.elapsedNanos=1000000000, request.http.method=GET, request.http.parameters.query.name=Dr. IntegrationTest, request.http.path.full=/hello-world, request.http.path.absolute=http://localhost:63842/hello-world, request.http.client.port=63855, request.http.headers.User-Agent=Jersey/2.25.1 (HttpUrlConnection 17.0.2), request.http.server.port=63842, request.http.client.host=127.0.0.1, request.resourceClass=com.example.helloworld.resources.HelloWorldResource, request.http.path.template=/hello-world, request.http.server.name=localhost, request.http.headers.Host=localhost:63842, response.http.headers.Content-Type=application/json, response.http.contentType=application/json, response.http.entityType=com.example.helloworld.api.Saying, response.http.status.code=200, request.http.client.address=127.0.0.1, request.resourceMethod=sayHello, response.http.status.phrase=OK, response.http.body={ \"id\" : 1, \"content\" : \"Hello, Dr. IntegrationTest!\" }, response.http.contentLength=59, request.http.server.scheme=http, response.http.status.status=OK, response.http.status.family=SUCCESSFUL> Logstash encoder liftwizard-config-logging-logstash-file is a Dropwizard AppenderFactory . It sets up a file appender that logs one json object per log statement. The json is formatted by https://github.com/logstash/logstash-logback-encoder logstash-logback-encoder and is ready to be parsed by logstash.Let's add the logstash-file appender to the list of configured appenders. test-example.json5 src/test/resources/test-example.json5 json5 { // ... \"logging\": { \"level\": \"DEBUG\", \"appenders\": [ { \"type\": \"console\", \"timeZone\": \"${LOGGING_TIMEZONE:-system}\", \"logFormat\": \"%highlight(%-5level) %cyan(%date{HH:mm:ss.SSS, %dwTimeZone}) %gray(\\\\(%file:%line\\\\)) [%white(%thread)] %blue(%marker) {%magenta(%mdc)} %green(%logger): %message%n%rootException\", \"includeCallerData\": true, }, { \"type\" : \"file-logstash\", \"currentLogFilename\" : \"./logs/logstash.jsonl\", \"archivedLogFilenamePattern\": \"./logs/logstash-%d.jsonl\", \"includeCallerData\" : true, \"encoder\": { \"includeContext\": true, \"includeMdc\": true, \"includeStructuredArguments\": true, \"includedNonStructuredArguments\": true, \"includeTags\": true, \"prettyPrint\": false, } } ] }, // ... } logstash.jsonl logs/logstash.jsonl snippet"],["logging@@buffered-logging@@","Logging","Buffered Logging","","In unit tests, it can be useful to suppress all logging for successful tests, but still log everything when tests fail.In order to accomplish this, we need to buffer all logging before we know the result of the test, and then flush or clear the buffer once we know the outcome. BufferedAppender BufferedAppender is the logback appender that buffers all logging until it receives a CLEAR or FLUSH marker.You can use directly in logback configuration. It requires a delegate appender for flushing, declared using an appender-ref . BufferedAppender lives in the liftwizard-logging-buffered-appender module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-logging-buffered-appender</artifactId> <scope>test</scope> </dependency> Log Markers We must log CLEAR and FLUSH markers to instruct BufferedAppender to clear or flush its logs. If you are using JUnit 4 or 5, you can use the included Rule or Extension to log these markers automatically. JUnit 4 LogMarkerTestRule is a JUnit 4 Rule that clears the buffer before all tests and flushes the buffer after failed tests. It does this by logging CLEAR and FLUSH markers. java public class ExampleTest { @Rule public final TestRule logMarkerTestRule = new LogMarkerTestRule(); @Test public void smokeTest() { // test code } } LogMarkerTestRule lives in the liftwizard-junit-rule-log-marker module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-junit-rule-log-marker</artifactId> <scope>test</scope> </dependency> JUnit 5 LogMarkerTestExtension is a JUnit 5 Extension that clears the buffer before all tests and flushes the buffer after failed tests. It does this by logging CLEAR and FLUSH markers. java @ExtendWith(LogMarkerTestExtension.class) public class ExampleTest { @Test public void smokeTest() { // test code } } LogMarkerTestExtension lives in the liftwizard-junit-extension-log-marker module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-junit-extension-log-marker</artifactId> <scope>test</scope> </dependency> BufferedAppenderFactory The BufferedAppenderFactory allows you to use an appender with the type buffered where you would otherwise use console in your Dropwizard configuration. json5 \"logging\": { \"level\": \"DEBUG\", \"appenders\": [ { \"type\": \"buffered\", \"timeZone\": \"${LOGGING_TIMEZONE:-system}\", \"logFormat\": \"%highlight(%-5level) %cyan(%date{HH:mm:ss.SSS, %dwTimeZone}) %gray(\\\\(%file:%line\\\\)) [%white(%thread)] %blue(%marker) {%magenta(%mdc)} %green(%logger): %message%n%rootException\", \"includeCallerData\": true, }, ] } BufferedAppenderFactory lives in the liftwizard-config-logging-buffered module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-config-logging-buffered</artifactId> <scope>test</scope> </dependency> Note: BufferedAppenderFactory is primarily useful for tests that use https://www.dropwizard.io/en/release-2.1.x/manual/testing.html#junit-4 Dropwizard's JUnit 4 Rule DropwizardAppRule or https://www.dropwizard.io/en/release-2.1.x/manual/testing.html#junit-5 Dropwizard's JUnit 5 Extension DropwizardAppExtension . java private final TestRule logMarkerTestRule = new LogMarkerTestRule(); private final DropwizardAppRule<HelloWorldConfiguration> dropwizardAppRule = new DropwizardAppRule<>( HelloWorldApplication.class, ResourceHelpers.resourceFilePath(\"test-example.json5\")); @Rule public final RuleChain ruleChain = RuleChain .outerRule(this.dropwizardAppRule) .around(this.logMarkerTestRule); Note: LogMarkerTestRule needs to be an inner rule, with any other rules that tear down logging outer to it."],["logging@@filter-factories@@","Logging","Filter Factories","","Dropwizard comes with support for dynamic configuration of https://www.dropwizard.io/en/latest/manual/core.html#logging-filters log filters. However, it ships with just a single filter, the https://www.dropwizard.io/en/latest/manual/core.html#filtering-request-logs-for-a-specific-uri UriFilterFactory.One can create logging filters that will intercept log statements before they are written and decide if theyâ€™re allowed. Log filters can work on both regular statements and request log statements.Liftwizard provides an improved RequestUrlFilterFactory for request logs and JaninoFilterFactory for plain logs. RequestUrlFilterFactory RequestUrlFilterFactory is an improved version of UriFilterFactory . It can filter access logs that do or don't match a list of urls.To use it, add a dependency on liftwizard-config-logging-filter-requesturl . Then add a filter factory to your config with type url and a list of urls to include or exclude. The default value of onMatch is ch.qos.logback.core.spi.FilterReply.DENY . JaninoFilterFactory JaninoFilterFactory allows you to specify the filter condition in a snippet of Java code that gets compiled with https://janino-compiler.github.io/janino/ Janino.To use it, add a dependency on liftwizard-config-logging-filter-janino . Then add a filter factory to your config with type janino and a javaExpression that evaluates to a boolean. The default value of onMatch is ch.qos.logback.core.spi.FilterReply.DENY . json5 { \"logging\": { \"level\": \"DEBUG\", \"appenders\": [ { \"type\": \"console\", \"timeZone\": \"${LOGGING_TIMEZONE:-system}\", \"logFormat\": \"%highlight(%-5level) %cyan(%date{HH:mm:ss.SSS, %dwTimeZone}) %gray(\\\\(%file:%line\\\\)) [%white(%thread)] %blue(%marker) {%magenta(%mdc)} %green(%logger): %message%n%rootException\", \"filterFactories\": [ { \"type\": \"janino\", \"javaExpression\": \"logger.equals(\\\"io.liftwizard.logging.p6spy.P6SpySlf4jLogger\\\") && mdc.get(\\\"liftwizard.bundle\\\").equals(\\\"DdlExecutorBundle\\\")\", \"onMatch\": \"DENY\" } ] } ] } }"],["logging@@Slf4jUncaughtExceptionHandlerBundle@@the-logs","Logging","Slf4jUncaughtExceptionHandlerBundle","The logs","Slf4jUncaughtExceptionHandler is an https://docs.oracle.com/en%2Fjava%2Fjavase%2F21%2Fdocs%2Fapi%2F%2F/java.base/java/lang/Thread.UncaughtExceptionHandler.html UncaughtExceptionHandler that logs uncaught exceptions using SLF4J. Slf4jUncaughtExceptionHandlerBundle is a Dropwizard bundle that installs Slf4jUncaughtExceptionHandler on startup.When a thread is about to terminate due to an uncaught exception the Java Virtual Machine will query the thread for its UncaughtExceptionHandler using Thread.getUncaughtExceptionHandler() and will invoke the handler's uncaughtException method, passing the thread and the exception as arguments.When an uncaught exception is thrown, Slf4jUncaughtExceptionHandler logs the exception at the WARN level.With logback configuration like this: xml <appender name=\"Console\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%highlight(%-5level) %cyan(%date{HH:mm:ss.SSS, ${LOGGING_TIMEZONE}}) %gray(\\(%file:%line\\)) [%white(%thread)] %blue(%marker) {%magenta(%mdc)} %green(%logger): %message%n%rootException</pattern> </encoder> </appender> The logs look like this: shell WARN 12:00:00.000 (Slf4jUncaughtExceptionHandler.java:46) [main] {exceptionClass=io.liftwizard.logging.slf4j.uncaught.exception.handler.Slf4jUncaughtExceptionHandlerTest.RootException, liftwizard.error.message=example root, liftwizard.error.kind=io.liftwizard.logging.slf4j.uncaught.exception.handler.Slf4jUncaughtExceptionHandlerTest.RootException, threadName=main, exceptionMessage=example root, liftwizard.error.thread=main} io.liftwizard.logging.slf4j.uncaught.exception.handler.Slf4jUncaughtExceptionHandler: Exception in thread \"main\" io.liftwizard.logging.slf4j.uncaught.exception.handler.Slf4jUncaughtExceptionHandlerTest$CauseException: example cause at io.liftwizard.logging.slf4j.uncaught.exception.handler.Slf4jUncaughtExceptionHandlerTest.testUncaughtException(Slf4jUncaughtExceptionHandlerTest.java:26) ~[test-classes/:na] ... 68 common frames omitted Wrapped by: io.liftwizard.logging.slf4j.uncaught.exception.handler.Slf4jUncaughtExceptionHandlerTest$RootException: example root at io.liftwizard.logging.slf4j.uncaught.exception.handler.Slf4jUncaughtExceptionHandlerTest.testUncaughtException(Slf4jUncaughtExceptionHandlerTest.java:27) ~[test-classes/:na]"],["logging@@Slf4jUncaughtExceptionHandlerBundle@@with-dropwizard","Logging","Slf4jUncaughtExceptionHandlerBundle","With Dropwizard","To use the exception handler with Dropwizard, add Slf4jUncaughtExceptionHandlerBundle to the list of registered bundles. java @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { bootstrap.addBundle(new Slf4jUncaughtExceptionHandlerBundle()); } And add the dependency: xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-bundle-logging-uncaught-exception-handler</artifactId> </dependency>"],["logging@@Slf4jUncaughtExceptionHandlerBundle@@without-dropwizard","Logging","Slf4jUncaughtExceptionHandlerBundle","Without Dropwizard","To use Slf4jUncaughtExceptionHandler without the bundle, create an instance and set it as the default uncaught exception handler. java Thread.setDefaultUncaughtExceptionHandler(new Slf4jUncaughtExceptionHandler()); And add the dependency: xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-logging-uncaught-exception-handler</artifactId> </dependency>"],["graphql@@bundle@@","Graphql","Bundle","","The LiftwizardGraphQLBundle extends com.smoketurner.dropwizard.graphql.GraphQLBundle .The bundle registers https://github.com/graphql/graphiql the GraphIQL UI at /graphiql and https://github.com/graphql/graphql-playground the GraphQL Playground UI at /graphql-playground , by delegating to AssetsBundle . This overrides the behavior of the smoketurner bundle, which registers just one UI at / (graphiql in older versions, and graphql-playground in newer versions).The bundle also registers two instrumentations for logging and metrics. If you choose not to use the bundle, you can still register the instrumentations separately.To turn it on, add LiftwizardGraphQLBundle to the list of registered bundles. java @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { bootstrap.setConfigurationFactoryFactory(new JsonConfigurationFactoryFactory<>()); bootstrap.addBundle(new EnvironmentConfigBundle()); bootstrap.addBundle(new ObjectMapperBundle()); bootstrap.addBundle(new ConfigLoggingBundle()); bootstrap.addBundle(new JerseyHttpLoggingBundle()); bootstrap.addBundle(new LiftwizardGraphQLBundle<>( builder -> { // TODO: Set up GraphQL wiring // builder.scalar(...); // builder.type(...); })); // ... } LiftwizardGraphQLBundle lives in the liftwizard-bundle-graphql module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-bundle-graphql</artifactId> </dependency>"],["graphql@@instrumentation-logging@@","Graphql","Instrumentation Logging","","LiftwizardGraphQLLoggingInstrumentation is an implementation of Instrumentation from https://www.graphql-java.com/ GraphQL Java that adds helpful context to slf4j's http://www.slf4j.org/manual.html#mdc Mapped Diagnostic Context .For example, say that during the execution of a DataFetcher , we execute a database query and log its sql. It would be helpful to see the query in the context of the DataFetcher that executed it, along with the GraphQL field and its type, and the path we took through the graph on the way to this field.This Instrumentation adds these fields to MDC, prefixed with liftwizard.graphql .To turn it on, either run the entire graphql/bundle.md LiftwizardGraphQLBundle or just add LiftwizardGraphQLLoggingInstrumentation to the list of instrumentations on your GraphQLFactory . java GraphQLFactory factory = ...; var loggingInstrumentation = new LiftwizardGraphQLLoggingInstrumentation(); List<Instrumentation> instrumentations = List.of(loggingInstrumentation); factory.setInstrumentations(instrumentations); Here's an example of what SQL logging might look like with MDC attached when formatted by the \"file-logstash\" appender. LiftwizardGraphQLLoggingInstrumentation lives in the liftwizard-graphql-instrumentation-logging module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-graphql-instrumentation-logging</artifactId> </dependency>"],["graphql@@instrumentation-metrics@@","Graphql","Instrumentation Metrics","","LiftwizardGraphQLMetricsInstrumentation is an implementation of Instrumentation from https://www.graphql-java.com/ GraphQL Java that registers https://metrics.dropwizard.io/ performance metrics about data fetching with Dropwizard's MetricsRegistry.To turn it on, either run the entire graphql/bundle.md LiftwizardGraphQLBundle or just add LiftwizardGraphQLMetricsInstrumentation to the list of instrumentations on your GraphQLFactory . java GraphQLFactory factory = ...; Clock clock = Clock.systemUTC(); var metricsInstrumentation = new LiftwizardGraphQLMetricsInstrumentation(this.metricRegistry, clock); var loggingInstrumentation = new LiftwizardGraphQLLoggingInstrumentation(); List<Instrumentation> instrumentations = List.of(metricsInstrumentation, loggingInstrumentation); factory.setInstrumentations(instrumentations); Annotations Next, annotate the DataFetchers that you want to monitor with @Timed , @Metered , and/or @ExceptionMetered . You can annotate either the get() method, or the entire fetcher class. Timers @Timed adds three timers:{DataFetcher's fully-qualified class name}.get.sync liftwizard.graphql.field.{GraphQL Class}.{GraphQL field}.sync liftwizard.graphql.path.{path}.sync All three timers track the number of times each DataFetcher is called, and the amount of time spent in the get() method.Although the timers measure the same thing, they may not have identical values. This would happen if the same DataFetcher is wired to multiple fields, or is reached by multiple paths through the graph.If your DataFetcher returns https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/CompletableFuture.html CompleteableFuture , you'll get three additional timers, with names ending in \"async\" instead of \"sync\". Rather than track the amount of time spent in get() , these timers will track the amount of time until the CompleteableFutures complete. Meters Timers are meters, so if you want to know the number of times a fetcher is called, annotate them with @Timer.If you annotate your DataFetcher with @Metered , the Intrumentation will add meters that track the number of items returned by the DataFetcher. If the DataFetcher returns a Collection or CompleteableFuture<Collection> , the meter will increment by the size of the Collection. ExceptionMeters @ExceptionMetered adds meters that track the number of times the DataFetcher throws uncaught exceptions, plus the number of CompleteableFutures they return that complete exceptionally. The meters have the same names as the timers, but with the suffix \"exceptions\":{DataFetcher's fully-qualified class name}.get.exceptions liftwizard.graphql.field.{GraphQL Class}.{GraphQL field}.exceptions liftwizard.graphql.path.{path}.exceptions LiftwizardGraphQLMetricsInstrumentation lives in the liftwizard-graphql-instrumentation-metrics module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-graphql-instrumentation-metrics</artifactId> </dependency>"],["graphql@@data-fetcher-async@@","Graphql","Data Fetcher Async","","LiftwizardAsyncDataFetcher is an enhanced alternative to AsyncDataFetcher from https://www.graphql-java.com/ GraphQL Java.Both have the ability to wrap a synchronous DataFetcher together with an Executor , and return CompleteableFuture s that execute on the Executor . LiftwizardAsyncDataFetcher also copies slf4j's http://www.slf4j.org/manual.html#mdc Mapped Diagnostic Context to the background tasks, and restores the MDC when each task completes. java builder.dataFetcher( \"fieldName\", LiftwizardAsyncDataFetcher.async(dataFetcher, executor)); When using Dropwizard, the executor should come from its environment. java ExecutorService executorService = environment .lifecycle() .executorService(\"my-data-fetcher-%d\") .maxThreads(maxThreads) .build(); LiftwizardAsyncDataFetcher lives in the liftwizard-graphql-data-fetcher-async module. xml <dependency> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-graphql-data-fetcher-async</artifactId> </dependency>"],["reladomo@@reladomo-operation-compiler@@","Reladomo","Reladomo Operation Compiler","","When using https://github.com/goldmansachs/reladomo Reladomo, queries are usually expressed using its code-generated Finder language. java Operation operation = MyTypeFinder.optionalString().eq(\"value\") .and(MyTypeFinder.optionalInteger().eq(4)); MyTypeList mithraList = MyTypeFinder.findMany(operation); In some situations, it can be useful to have a more dynamic way of expressing queries.That's where ReladomoOperationCompiler comes in. It can take a String and compile it into a Reladomo https://www.mvndoc.com/c/com.goldmansachs.reladomo/reladomo/com/gs/fw/finder/Operation.html Operation.In this example, this.stringProperty = \"value\" & this.integerProperty = 4 is the equivalent query.This can be used for dynamic ad-hoc queries, and combines well with graphql/bundle.md Liftwizard's GraphQL features. java MyTypeFinder finder = MyTypeFinder.getFinderInstance(); var operationText = \"this.stringProperty = \\\"value\\\" & this.integerProperty = 4\"; var compiler = new ReladomoOperationCompiler(); Operation operation = compiler.compile(finder, operationText); MyTypeList mithraList = MyTypeFinder.findMany(operation); Compiling toString() representation The syntax closely matches the toString() representation of Reladomo's Operations, with a little added flexibility. In general, you can call operation.toString() and compile the output to get back an equivalent Operation. java Operation operation = ...; String operationText = operation.toString(); Operation recompiled = compiler.compile(finder, operationText); assertThat(recompiled, is(operation)); Error messages The compiler is designed to give helpful error messages on inputs that parse but don't compile.For example, running the compiler on this.invalidAttributeName = \"Value\" might throw an error like: text Could not find attribute 'invalidAttributeName' on type 'MyType' in this.invalidAttributeName = \"Value\". Valid attributes: [idProperty, stringProperty, integerProperty, longProperty, doubleProperty, floatProperty, booleanProperty, instantProperty, localDateProperty, createdById, createdOn, lastUpdatedById, systemFrom, systemTo] Flexible syntax The compiler allows some flexibility in the syntax. toString() Alternatives `&` `&&`, `and` `|` `||`, `or` `<class name>` `this` `lower` `toLowerCase` `abs` `absoluteValue` `=` `==`, `eq` `!=` `not eq`, `notEq` `>` `greaterThan` `>=` `greaterThanEquals` `<` `lessThan` `<=` `lessThanEquals` `not in` `notIn` `not startsWith` `notStartsWith` `not endsWith` `notEndsWith` `not contains` `notContains` `not wildCardEquals` `wildCardNotEquals` `is null` `== null` `is not null` `!= null` `all of <class name}` `all` Complete examples # Attribute types this.booleanProperty = true this.integerProperty = 4 this.longProperty = 5 this.floatProperty = 6.6 this.doubleProperty = 7.7 this.dateProperty = \"2010-12-31\" this.timeProperty = \"2010-12-31T23:59:00.0Z\" this.stringProperty = \"Value\" this.system = \"2010-12-31T23:59:00.0Z\" # Conjunctions this.booleanProperty = true & this.integerProperty = 4 this.booleanProperty = true && this.integerProperty = 4 this.booleanProperty = true and this.integerProperty = 4 this.booleanProperty = true | this.integerProperty = 4 this.booleanProperty = true || this.integerProperty = 4 this.booleanProperty = true or this.integerProperty = 4 # Equality operators this.stringProperty = \"Value\" this.stringProperty != \"Value\" this.stringProperty is null this.stringProperty == null this.stringProperty is not null this.stringProperty != null this.stringProperty in [\"Value\", \"Value2\", null] this.stringProperty not in [\"Value\", \"Value2\", null] # String operators this.stringProperty endsWith \"Value\" this.stringProperty contains \"Value\" this.stringProperty startsWith \"Value\" this.stringProperty wildCardEquals \"Value?\" this.stringProperty not endsWith \"Value\" this.stringProperty not contains \"Value\" this.stringProperty not startsWith \"Value\" this.stringProperty not wildCardEquals \"Value?\" # Numeric operators this.stringProperty > \"Value\" this.stringProperty >= \"Value\" this.stringProperty < \"Value\" this.stringProperty <= \"Value\" # Functions / derived attributes toLowerCase(this.stringProperty) = \"value\" substring(this.stringProperty, 2, 3) = \"value\" substring(toLowerCase(this.stringProperty), 2, 3) = \"value\" # Flexible number literals this.floatProperty = 42.0f this.floatProperty = 42.0d this.floatProperty = 42 this.doubleProperty = 42.0f this.doubleProperty = 42.0d this.doubleProperty = 42 this.longProperty = 10_000_000_000 this.integerProperty = 1_000_000_000 # Number / date functions / derived attributes abs(this.integerProperty) = 1 year(this.timeProperty) = 1999 month(this.timeProperty) = 12 dayOfMonth(this.timeProperty) = 31 year(this.dateProperty) = 1999 month(this.dateProperty) = 12 dayOfMonth(this.dateProperty) = 31 # Relationships this.target.value = \"value\" this.target exists this.target not exists this.target { RelatedType.source.value = \"value\" } not exists # Edge points this.system equalsEdgePoint"],["database@@named-data-source@@","Database","Named Data Source","","Dropwizard provides an interface called ManagedDataSource . public interface ManagedDataSource extends DataSource, Managed { } It's just a io.dropwizard.lifecycle.Managed and a javax.sql.DataSource . It's a DataSource with start/stop lifecycle methods. ManagedDataSource works well when you have one of them. When you have multiple data sources, it can be difficult to tie them together through configuration. For example, if you use Liquibase for migrations, https://www.dropwizard.io/en/latest/manual/migrations.html#support-for-adding-multiple-migration-bundles you'd need to write code to tie specific migrations to specific data sources; it cannot be done through configuration alone.Liftwizard provides NamedDataSource , which is a ManagedDataSource with a name. liquibase-migrations.md Other Liftwizard bundles expect NamedDataSource s to be configured, and refer to them by name in their own configuration. In the liquibase example, we could tie specific migrations to specific data sources through configuration alone.Different named data sources can refer to different databases, or the same database configured different ways. In the following example, we have one data source for Postgres, and three data sources to connect to h2; over the network, in-memory, and on disk.To use named data sources, start by changing the Configuration class to implement NamedDataSourceFactoryProvider . java public class HelloWorldConfiguration extends Configuration implements NamedDataSourceProvider // , ... other interfaces { // ... } Add a field with type NamedDataSourcesFactory . @JsonUnwrapped private @Valid @NotNull NamedDataSourcesFactory namedDataSourcesFactory = new NamedDataSourcesFactory(); Add the getter/setter required by the interface. @JsonProperty(\"dataSources\") @JsonUnwrapped public NamedDataSourcesFactory getNamedDataSourcesFactory() { return this.namedDataSourcesFactory; } @JsonProperty(\"dataSources\") @JsonUnwrapped public void setNamedDataSourcesFactory(NamedDataSourcesFactory namedDataSourcesFactory) { this.namedDataSourcesFactory = namedDataSourcesFactory; } Now we can use the named data sources in the configuration of other bundles. For example, we use the data source named h2-tcp in the liquibase configuration."],["database@@liquibase-migrations@@","Database","Liquibase Migrations","","Dropwizard ships with a https://www.dropwizard.io/en/latest/manual/migrations.html dropwizard-migrations bundle.The dropwizard-migrations module provides you with a wrapper for https://www.liquibase.org/ Liquibase database refactoring.The built-in bundle provides Dropwizard Commands, for a command line interface to run migrations. It does not provide a way to run migrations on application startup. That's where Liftwizard comes in.To run migrations with Dropwizard, you run a command like java -jar hello-world.jar db migrate helloworld.yml .To run migrations with Liftwizard, you run the usual server command, and Liftwizard will run migrations on startup.There are pros and cons of tying migrations to application startup. The main pros are that you don't have to remember to run migrations, and that they apply to embedded databases in tests. The main con is that migrations can take a long time, and you may not want to block application startup.To turn it on, add LiftwizardLiquibaseMigrationBundle to the list of registered bundles. java @Override public void initialize(Bootstrap<HelloWorldConfiguration> bootstrap) { // ... bootstrap.addBundle(new LiftwizardLiquibaseMigrationBundle()); // ... } Change the Configuration class to implement LiquibaseMigrationFactoryProvider . java public class HelloWorldConfiguration extends Configuration implements LiquibaseMigrationFactoryProvider // , ... other interfaces { // ... } Add a field with type LiquibaseMigrationFactory . private @Valid @NotNull LiquibaseMigrationFactory liquibaseMigrationFactory = new LiquibaseMigrationFactory(); Add the getter/setter required by the interface. @JsonProperty(\"liquibase\") @Override public LiquibaseMigrationFactory getLiquibaseMigrationFactory() { return this.liquibaseMigrationFactory; } @JsonProperty(\"liquibase\") public void setLiquibaseMigrationFactory(LiquibaseMigrationFactory liquibaseMigrationFactory) { this.liquibaseMigrationFactory = liquibaseMigrationFactory; } Configuration The LiftwizardLiquibaseMigrationBundle requires that you're already using database/named-data-source named data sources.Add a liquibase section to your configuration/json5-configuration json or yaml configuration. dataSourceMigrations is an array, to allow multiple migrations to different data sources.Each dataSourceMigration's dataSourceName must match a dataSource's name in the dataSources section.If no migrationFileName is specified, migrations.xml is the default. migrationFileLocation can be classpath or filesystem . classpath is the default. contexts are an array of Liquibase https://docs.liquibase.com/concepts/changelogs/attributes/contexts.html context tags.With this configuration in place, migrations will run on application startup."],["testing@@testing@@","Testing","Testing","","Liftwizard includes utilities for asserting that a string equals the contents of a file.\"slurping\" the file into a string file matching: exact string comparison json matching: json comparison rerecord mode These utilities are implemented as JUnit 4 Rules and JUnit 5 Extensions."],["testing@@matching-files@@","Testing","Matching Files","","Liftwizard includes utilities for asserting that a string equals the contents of a file.If your code has changed enough, it can be more convenient to re-record the test resource files, and review the changes using git diff rather than the test assertion errors. To enable re-record mode, set the environment variable LIFTWIZARD_FILE_MATCH_RULE_RERECORD to true .The setup is different for the JUnit 4 Rule and JUnit 5 Extension. After setup, both have the same API. java this.fileMatchExtension.assertFileContents(expectedStringClassPathLocation, actualString); If the file does not exist, or the contents do not match, an assertion error is added to an https://junit.org/junit4/javadoc/4.12/org/junit/rules/ErrorCollector.html ErrorCollector. If the ErrorCollector contains any errors, the test fails at the end with all expected/actual pairs reported together.If LIFTWIZARD_FILE_MATCH_RULE_RERECORD is set to true , assertFileContents will not emit any AssertionErrors . JUnit 4 java public class ExampleTest { @Rule public final FileMatchRule fileMatchRule = new FileMatchRule(this.getClass()); @Test public void smokeTest() { String resourceClassPathLocation = this.getClass().getSimpleName() + \".txt\"; this.fileMatchRule.assertFileContents(resourceClassPathLocation, \"test content\"); } } JUnit 5 java public class ExampleTest { @RegisterExtension private final FileMatchExtension fileMatchExtension = new FileMatchExtension(this.getClass()); @Test public void smokeTest() { String resourceClassPathLocation = this.getClass().getSimpleName() + \".txt\"; this.fileMatchExtension.assertFileContents(resourceClassPathLocation, \"test content\"); } }"],["testing@@matching-json@@","Testing","Matching Json","","Liftwizard includes utilities for asserting that a JSON string equals the contents of a file, using JSON equality semantics. Liftwizard delegates to https://github.com/skyscreamer/JSONassert JSONassert for JSON comparison.The API is similar to the ./matching-files file matching API, and re-record mode is enabled with the same environment variable LIFTWIZARD_FILE_MATCH_RULE_RERECORD .The setup is different for the JUnit 4 Rule and JUnit 5 Extension. After setup, both have the same API. java this.jsonMatchExtension.assertFileContents(expectedJsonClassPathLocation, actualJson); If the file does not exist, or the contents do not match, an assertion error is added to an https://junit.org/junit4/javadoc/4.12/org/junit/rules/ErrorCollector.html ErrorCollector. If the ErrorCollector contains any errors, the test fails at the end with all expected/actual pairs reported together.If LIFTWIZARD_FILE_MATCH_RULE_RERECORD is set to true , assertJsonContents will not emit any AssertionErrors . JUnit 4 JsonMatchRule works well with Dropwizard's https://www.dropwizard.io/en/release-2.1.x/manual/testing.html#junit-4 DropwizardAppRule . java public class ExampleTest { @Rule private final DropwizardAppRule<HelloWorldConfiguration> dropwizardAppRule = new DropwizardAppRule<>( ExampleApplication.class, ResourceHelpers.resourceFilePath(\"config-test.json5\")); @Rule public final JsonMatchRule jsonMatchRule = new JsonMatchRule(this.getClass()); @Test public void smokeTest() { Response actualResponse = this.dropwizardAppRule .client() .target(\"http://localhost:{port}/api/example\") .resolveTemplate(\"port\", this.dropwizardAppRule.getLocalPort()) .request() .get(); String actualJsonResponse = actualResponse.readEntity(String.class); String expectedResponseClassPathLocation = this.getClass().getSimpleName() + \".\" + testName + \".json\"; this.jsonMatchRule.assertFileContents(expectedResponseClassPathLocation, actualJsonResponse); } } JUnit 5 JsonMatchExtension works well with Dropwizard's https://www.dropwizard.io/en/stable/manual/testing.html#junit-5 DropwizardAppExtension or Liftwizard's LiftwizardAppExtension . java public class ExampleTest { @RegisterExtension private final LiftwizardAppExtension<?> appExtension = this.getLiftwizardAppExtension(); @RegisterExtension private final JsonMatchExtension jsonMatchExtension = new JsonMatchExtension(this.getClass()); @Nonnull @Override private LiftwizardAppExtension<?> getLiftwizardAppExtension() { return new LiftwizardAppExtension<>( ExampleApplication.class, ResourceHelpers.resourceFilePath(\"config-test.json5\")); } @Test public void smokeTest() { Response actualResponse = this.appExtension .client() .target(\"http://localhost:{port}/api/example\") .resolveTemplate(\"port\", this.appExtension.getLocalPort()) .request() .get(); String actualJsonResponse = actualResponse.readEntity(String.class); String expectedResponseClassPathLocation = this.getClass().getSimpleName() + \".\" + testName + \".json\"; this.jsonMatchExtension.assertFileContents(expectedResponseClassPathLocation, actualJsonResponse); } }"],["maven@@maven-best-practices@@","Maven","Maven Best Practices","","There are a number of best practices that can be handled at once by inheriting from a parent pom that takes care of them all.Liftwizard ships with several parent poms that form an inheritance hierarchy. minimal-parent.md liftwizard-minimal-parent is the most minimal parent pom. It is meant to contain uncontroversial best practices that are applicable to all projects. profile-parent.md liftwizard-profile-parent is a parent pom that inherits from liftwizard-minimal-parent and enables several linters and validators in profiles that are off by default. bill-of-materials.md liftwizard-bom is a https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#bill-of-materials-bom-poms Bill of Materials (BOM) that exports all modules within Liftwizard. liftwizard-parent is a parent pom that inherits from liftwizard-profile-parent , selects versions of libraries related to Dropwizard applications, and includes opinionated configurations for plugins. Learning Maven Maven can be confusing due to the extent of the \"convention over configuration\" approach.For example, to answer \"how does maven run compilation before tests\" you would need to learn:Plugins which are bound and enabled by default maven-surefire-plugin is the plugin that handles tests maven-compiler-plugin binds to the compile and testCompile phases. maven-surefire-plugin binds to the test phase In the https://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html#default-lifecycle lifecycle phases compile comes before testCompile which comes before test . None of this information appears in pom.xml , and little of it is logged during the build.To make it easier to understand, liftwizard-minimal-parent includes region markers surrounding each plugin that label the phase that the plugin is bound to. The sections are sorted by phase. <!--region Phase 22: install--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-install-plugin</artifactId> <version>3.1.2</version> </plugin> <!--endregion Phase 22: install-->"],["maven@@minimal-parent@@usage","Maven","Minimal Parent","Usage","The most minimal parent pom is liftwizard-minimal-parent . If you are able to accept more opinionated defaults, continue to profile-parent liftwizard-profile-parent . The minimal parent is meant to contain uncontroversial best practices that are applicable to all projects.Inherit from liftwizard-minimal-parent in your project's pom.xml: xml <parent> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-minimal-parent</artifactId> <version>${liftwizard.version}</version> </parent>"],["maven@@minimal-parent@@what-you-will-get","Maven","Minimal Parent","What you will get","The following sections describe the best practices that are enforced by liftwizard-minimal-parent . You will not need to configure these in your project's pom.xml if you inherit from liftwizard-minimal-parent ."],["maven@@minimal-parent@@resource-encodings","Maven","Minimal Parent","Resource encodings","If you encounter a warning like: [WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent! this is because the project does not https://maven.apache.org/plugins/maven-resources-plugin/examples/encoding.html#specifying-a-character-encoding-scheme specify a character encoding scheme to configure maven-resources-plugin . liftwizard-minimal-parent specifies the character encoding scheme in the properties section of the pom.xml. <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding> <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding> This will become unnecessary starting with maven 4.x."],["maven@@minimal-parent@@reproducible-builds","Maven","Minimal Parent","Reproducible builds","https://reproducible-builds.org/ Reproducible builds are a set of software development practices that create an independently-verifiable path from source to binary code. A build is reproducible if given the same source code, build environment and build instructions, any party can recreate bit-by-bit identical copies of all specified artifacts.You can https://maven.apache.org/guides/mini/guide-reproducible-builds.html#how-do-i-configure-my-maven-build enable Reproducible Builds mode for plugins by specifying locking down the outputTimestamp property. <project.build.outputTimestamp>2024-07-27T17:28:12Z</project.build.outputTimestamp> You will also need to run mvn artifact:check-buildplan and mvn verify artifact:compare as described in the guide to validate that builds are truly reproducible."],["maven@@minimal-parent@@default-goal","Maven","Minimal Parent","Default Goal","You can specify the default goal to run when you run mvn without any arguments. <defaultGoal>verify</defaultGoal> verify is a better choice than install in the presence of concurrent builds that may write to .m2/repository simultaneously. verify is a better choice than clean verify because developers may build up state like test files and test databases under target/ and may not expect them to be deleted by default. It's easy to run mvn clean when you need it."],["maven@@minimal-parent@@plugins-which-are-bound-and-enabled-by-default","Maven","Minimal Parent","Plugins which are bound and enabled by default","Maven builds are configured by binding plugins to https://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html#default-lifecycle lifecycle phases. Even if you don't declare any plugins in your pom.xml, maven will still bind https://maven.apache.org/ref/3.9.6/maven-core/default-bindings.html#plugin-bindings-for-jar-packaging some plugins to the https://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html#packaging \"main\" phases.All versions of maven bind the https://maven.apache.org/ref/3.9.6/maven-core/default-bindings.html#plugin-bindings-for-jar-packaging same plugins, but newer versions of maven bind newer versions of the plugins. If you don't specify the versions of the plugins, different members of the team could be using different versions, leading to different build results on different machines.It's becoming more common to lock down the version of maven itself, but this wasn't always the case. If you haven't specified the versions of these plugins, https://maven.apache.org/enforcer/enforcer-rules/requirePluginVersions.html maven-enforcer-plugin will log an error like: [ERROR] Rule 3: org.apache.maven.enforcer.rules.RequirePluginVersions failed with message: Some plugins are missing valid versions or depend on Maven 3.9.5 defaults (LATEST, RELEASE as plugin version are not allowed) org.apache.maven.plugins:maven-compiler-plugin. The version currently in use is 3.11.0 via default lifecycle bindings org.apache.maven.plugins:maven-surefire-plugin. The version currently in use is 3.1.2 via default lifecycle bindings org.apache.maven.plugins:maven-jar-plugin. The version currently in use is 3.3.0 via default lifecycle bindings org.apache.maven.plugins:maven-clean-plugin. The version currently in use is 3.2.0 via default lifecycle bindings org.apache.maven.plugins:maven-install-plugin. The version currently in use is 3.1.1 via default lifecycle bindings org.apache.maven.plugins:maven-site-plugin. The version currently in use is 3.12.1 via default lifecycle bindings org.apache.maven.plugins:maven-resources-plugin. The version currently in use is 3.3.1 via default lifecycle bindings org.apache.maven.plugins:maven-deploy-plugin. The version currently in use is 3.1.1 via default lifecycle bindings To avoid this, we specify versions of the plugins in the parent pom. <!-- These plugins are bound and enabled by default --> <!-- But the default version of these plugins changes with the version of maven running --> <!--region Phase 0: clean--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-clean-plugin</artifactId> <version>3.4.0</version> </plugin> <!--endregion Phase 0: clean--> <!--region Phase 6: process-resources--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-resources-plugin</artifactId> <version>3.3.1</version> </plugin> <!--endregion Phase 6: process-resources--> <!--region Phase 7: compile--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-compiler-plugin</artifactId> <version>3.13.0</version> <configuration> <!-- https://maven.apache.org/plugins-archives/maven-compiler-plugin-3.8.1/compile-mojo.html#parameters --> <!-- https://stackoverflow.com/a/44075684/ --> <!-- https://docs.oracle.com/javase/9/tools/javac.htm --> <!-- Generates metadata for reflection on method parameters. Stores formal parameter names of constructors and methods in the generated class file so that the method java.lang.reflect.Executable.getParameters from the Reflection API can retrieve them. --> <parameters>true</parameters> </configuration> </plugin> <!--endregion Phase 7: compile--> <!--region Phase 15: test--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-surefire-plugin</artifactId> <version>3.3.1</version> <!-- In maven 3.9.6 and 4.x, maven is able to auto-detect JUnit and these dependencies are not required --> <!-- In maven 3.9.5, there is an internal exception inside surefire without these declared --> <!-- Even with newer versions of maven, it is advantageous to keep these declarations --> <!-- Without them, maven may only run JUnit 5 tests, in a project with both JUnit 4 and 5 --> <dependencies> <dependency> <groupId>org.junit.jupiter</groupId> <artifactId>junit-jupiter-engine</artifactId> <version>5.10.3</version> </dependency> <dependency> <groupId>org.junit.platform</groupId> <artifactId>junit-platform-engine</artifactId> <version>1.10.3</version> </dependency> <dependency> <groupId>org.junit.vintage</groupId> <artifactId>junit-vintage-engine</artifactId> <version>5.10.3</version> </dependency> </dependencies> <configuration> <!-- The compiler in the server VM now provides correct stack backtraces for all \"cold\" built-in exceptions. For performance purposes, when such an exception is thrown a few times, the method may be recompiled. After recompilation, the compiler may choose a faster tactic using preallocated exceptions that do not provide a stack trace. To disable completely the use of preallocated exceptions, use this new flag: -XX:-OmitStackTraceInFastThrow. --> <!-- https://stackoverflow.com/a/4659279/ --> <!-- The compiler in the server VM now provides correct stack backtraces for all \"cold\" built-in exceptions. For performance purposes, when such an exception is thrown a few times, the method may be recompiled. After recompilation, the compiler may choose a faster tactic using preallocated exceptions that do not provide a stack trace. To disable completely the use of preallocated exceptions, use this new flag: -XX:-OmitStackTraceInFastThrow. --> <!-- https://stackoverflow.com/a/4659279/ --> <!-- Add argLine to allow the Jacoco plugin to append without overriding the setting --> <!-- https://stackoverflow.com/a/39818768/ --> <argLine>-XX:-OmitStackTraceInFastThrow @{argLine}</argLine> <runOrder>random</runOrder> <trimStackTrace>false</trimStackTrace> </configuration> </plugin> <!--endregion Phase 15: test--> <!--region Phase 17: package--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-jar-plugin</artifactId> <version>3.4.2</version> </plugin> <!--endregion Phase 17: package--> <!--region Phase 22: install--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-install-plugin</artifactId> <version>3.1.2</version> </plugin> <!--endregion Phase 22: install--> <!--region Phase 23: deploy--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-deploy-plugin</artifactId> <version>3.1.2</version> </plugin> <!--endregion Phase 23: deploy-->"],["maven@@minimal-parent@@no-phase","Maven","Minimal Parent","No phase","The are a number of maven plugins with goals that are designed to be run interactively, rather than being bound to a phase in the pom.xml. For example, mvn dependency:tree prints a visual representation of the dependencies of the project, and mvn versions:set updates the versions of dependencies in the pom.xml.Any maven plugin can be run from the command line with mvn groupId:artifactId:version:goal , and configured using command line arguments, without it appearing in the pom.xml. For example, we can run the https://www.mojohaus.org/buildplan-maven-plugin/ buildplan-maven-plugin to list the plugins bound to each phase with this command: shell mvn org.codehaus.mojo:buildplan-maven-plugin:2.2.2:list If we configure the plugin in the pom.xml, we can run it with the syntax mvn phase:goal and add any configuration that would otherwise be specified with -D flags. shell mvn buildplan:list We configure several plugins in the parent pom.xml that are not bound to any phase. <!--mvn versions:display-dependency-updates--> <!--mvn versions:display-plugin-updates--> <!--mvn versions:display-property-updates--> <plugin> <groupId>org.codehaus.mojo</groupId> <artifactId>versions-maven-plugin</artifactId> <version>2.17.1</version> <configuration> <!-- Don't create pom.xml.versionsBackup files --> <generateBackupPoms>false</generateBackupPoms> <!-- Process all modules in a multi-module build, even aggregator modules without a parent-child relationship --> <!-- https://stackoverflow.com/a/49246337/23572 --> <processAllModules>true</processAllModules> </configuration> </plugin> <!--mvn dependency:tree--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-dependency-plugin</artifactId> <version>3.7.1</version> </plugin> <!--mvn buildplan:list--> <!--mvn buildplan:list-phase--> <!--mvn buildplan:list-plugin--> <plugin> <groupId>org.codehaus.mojo</groupId> <artifactId>buildplan-maven-plugin</artifactId> <version>2.2.2</version> <configuration> <!-- Default value is: deploy --> <tasks> <task>clean</task> <task>deploy</task> </tasks> <!-- print all phases, even if no mapping to an execution is available --> <showAllPhases>true</showAllPhases> </configuration> </plugin> <!--mvnw wrapper:wrapper -Dmaven=4.0.0-alpha-7--> <plugin> <artifactId>maven-wrapper-plugin</artifactId> <version>3.3.2</version> </plugin> <!--mvn clean release:clean release:prepare -DdevelopmentVersion=1.2.3-SNAPSHOT--> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-release-plugin</artifactId> <version>3.1.1</version> <configuration> <!-- Default value is: invoker --> <mavenExecutorId>forked-path</mavenExecutorId> <!-- Automatically assign submodules the parent version --> <autoVersionSubmodules>true</autoVersionSubmodules> <!-- Do not `git push` changes to the upstream repository --> <pushChanges>false</pushChanges> <!-- Format to use when generating the tag name --> <!-- Default value is: @{project.artifactId}-@{project.version} --> <tagNameFormat>@{project.version}</tagNameFormat> </configuration> </plugin>"],["maven@@profile-parent@@","Maven","Profile Parent","","The \"profile\" parent pom inherits from minimal-parent liftwizard-minimal-parent . If you are able to accept more opinionated defaults, continue to bill-of-materials bill-of-materials . The profile parent contains a number of plugins you may want to enable, each wrapped individually in a maven profile. Usage Inherit from liftwizard-profile-parent in your project's pom.xml: xml <parent> <groupId>io.liftwizard</groupId> <artifactId>liftwizard-profile-parent</artifactId> <version>${liftwizard.version}</version> </parent> What you will get The following sections describe the profiles that are added by liftwizard-profile-parent . You will not need to configure these in your project's pom.xml if you inherit from liftwizard-profile-parent . You can enable the profiles using mvn --activate-profiles <profile1>,<profile2>,... Active by default According to https://maven.apache.org/guides/introduction/introduction-to-profiles.html the docs:Profiles can be active by default using a configuration like the following in a POM. xml <profiles> <profile> <id>profile-name</id> <activation> <activeByDefault>true</activeByDefault> </activation> ... </profile> </profiles> This profile will automatically be active for all builds unless another profile in the same POM is activated using one of the previously described methods. All profiles that are active by default are automatically deactivated when a profile in the POM is activated on the command line or through its activation config.This is confusing for new users, who are first confused to find some profiles are enabled by default, and later confused to find out that they are no longer enabled. No profiles in liftwizard-profile-parent are active by default, and we recommend avoiding activeByDefault in your project's pom.xml too. maven-enforcer-plugin <profile> <id>maven-enforcer-plugin</id> <build> <plugins> <plugin> <artifactId>maven-enforcer-plugin</artifactId> <configuration> <rules> <dependencyConvergence /> <requirePluginVersions> <banLatest>true</banLatest> <banRelease>true</banRelease> <banSnapshots>false</banSnapshots> <unCheckedPluginList xml:space=\"preserve\"> org.apache.maven.plugins:maven-site-plugin, org.apache.maven.plugins:maven-deploy-plugin </unCheckedPluginList> </requirePluginVersions> <bannedDependencies> <excludes combine.children=\"append\"> <exclude>commons-logging-api</exclude> <exclude>commons-logging</exclude> <exclude>javax.activation:javax.activation-api</exclude> <exclude>javax.servlet:javax.servlet-api</exclude> <exclude>javax.validation:validation-api</exclude> <exclude>javax.ws.rs:javax.ws.rs-api</exclude> <exclude>javax.xml.bind:jaxb-api</exclude> <exclude>javax.xml.ws:jaxws-api</exclude> <exclude>org.apache.logging.log4j:log4j</exclude> <exclude>org.slf4j:jcl</exclude> <exclude>org.slf4j:nop</exclude> <exclude>org.slf4j:slf4j-jdk14</exclude> <exclude>org.slf4j:slf4j-simple</exclude> </excludes> </bannedDependencies> <banDuplicatePomDependencyVersions /> <banDuplicateClasses> <findAllDuplicates>true</findAllDuplicates> <ignoreWhenIdentical>true</ignoreWhenIdentical> </banDuplicateClasses> </rules> </configuration> <executions> <execution> <id>enforce</id> <goals> <goal>enforce</goal> </goals> </execution> </executions> </plugin> </plugins> </build> </profile> <profile> <id>prettier-check</id> <build> <plugins> <plugin> <groupId>com.hubspot.maven.plugins</groupId> <artifactId>prettier-maven-plugin</artifactId> <executions> <execution> <goals> <goal>check</goal> </goals> <phase>validate</phase> </execution> </executions> </plugin> </plugins> </build> </profile> <profile> <id>prettier-apply</id> <build> <plugins> <plugin> <groupId>com.hubspot.maven.plugins</groupId> <artifactId>prettier-maven-plugin</artifactId> <executions> <execution> <goals> <goal>write</goal> </goals> <phase>validate</phase> </execution> </executions> </plugin> </plugins> </build> </profile> <profile> <id>spotless-check</id> <properties> <spotless.check.skip>false</spotless.check.skip> </properties> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <executions> <execution> <goals> <goal>check</goal> </goals> <phase>validate</phase> </execution> </executions> </plugin> </plugins> </build> </profile> <profile> <id>spotless-apply</id> <properties> <spotless.check.skip>false</spotless.check.skip> </properties> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <executions> <execution> <goals> <goal>apply</goal> </goals> <phase>verify</phase> </execution> </executions> </plugin> </plugins> </build> </profile> <profile> <id>spotless-formats</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <formats> <format> <toggleOffOn /> <includes> <include>.gitattributes</include> <include>.gitignore</include> </includes> <trimTrailingWhitespace /> <endWithNewline /> <indent> <tabs>true</tabs> <spacesPerTab>4</spacesPerTab> </indent> </format> </formats> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-java-sort-imports</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <java> <toggleOffOn> <off>@formatter:off</off> <on>@formatter:on</on> </toggleOffOn> <importOrder> <!-- use an empty string for all the imports not specified explicitly, '|' to join group without blank line, and '\\#` prefix for static imports. --> <order>java,javax,,\\#com.diffplug,\\#java|\\#javax,\\#</order> </importOrder> <removeUnusedImports /> </java> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-java-unused-imports</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <java> <toggleOffOn> <off>@formatter:off</off> <on>@formatter:on</on> </toggleOffOn> <removeUnusedImports /> </java> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-prettier-java</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <java> <toggleOffOn> <off>@formatter:off</off> <on>@formatter:on</on> </toggleOffOn> <prettier> <devDependencies> <prettier>3.3.2</prettier> <prettier-plugin-java>2.6.0</prettier-plugin-java> </devDependencies> <config> <tabWidth>4</tabWidth> <printWidth>120</printWidth> <parser>java</parser> <plugins>prettier-plugin-java</plugins> </config> </prettier> </java> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-google-java-format</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <java> <toggleOffOn> <off>@formatter:off</off> <on>@formatter:on</on> </toggleOffOn> <googleJavaFormat> <version>1.22.0</version> <style>AOSP</style> <reflowLongStrings>false</reflowLongStrings> </googleJavaFormat> </java> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-java-cleanthat</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <java> <toggleOffOn> <off>@formatter:off</off> <on>@formatter:on</on> </toggleOffOn> <!-- Cleanthat will refactor code, but it may break style: apply it before formatter --> <cleanthat /> </java> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-antlr</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <antlr4> <toggleOffOn /> <antlr4Formatter /> </antlr4> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-sql</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <sql> <toggleOffOn /> <includes> <include>**/*.sql</include> </includes> <excludes> <exclude>**/target/**/*.sql</exclude> </excludes> <prettier> <devDependencies> <prettier-plugin-sql>0.18.1</prettier-plugin-sql> </devDependencies> <config> <plugins>prettier-plugin-sql</plugins> </config> </prettier> </sql> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-pom</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <pom> <toggleOffOn /> <sortPom> <expandEmptyElements>false</expandEmptyElements> <spaceBeforeCloseEmptyElement>true</spaceBeforeCloseEmptyElement> <keepBlankLines>true</keepBlankLines> <nrOfIndentSpace>4</nrOfIndentSpace> <!-- Sort order of elements: https://github.com/Ekryd/sortpom/wiki/PredefinedSortOrderProfiles--> <predefinedSortOrder>recommended_2008_06</predefinedSortOrder> <!-- Custom sort order of elements: https://raw.githubusercontent.com/Ekryd/sortpom/master/sorter/src/main/resources/custom_1.xml --> <sortOrderFile /> </sortPom> </pom> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-markdown</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <markdown> <toggleOffOn /> <includes> <include>**/*.md</include> </includes> <excludes> <exclude>**/target/**/*.md</exclude> </excludes> <flexmark /> </markdown> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-json</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <json> <toggleOffOn /> <includes> <include>**/*.json</include> <include>**/*.json5</include> </includes> <excludes> <exclude>**/target/**/*.json</exclude> <exclude>**/target/**/*.json5</exclude> <exclude>**/archetype-resources/**/*.json</exclude> <exclude>**/archetype-resources/**/*.json5</exclude> </excludes> <prettier> <config> <singleQuote>false</singleQuote> </config> </prettier> </json> </configuration> </plugin> </plugins> </build> </profile> <profile> <id>spotless-yaml</id> <build> <plugins> <plugin> <groupId>com.diffplug.spotless</groupId> <artifactId>spotless-maven-plugin</artifactId> <configuration> <yaml> <toggleOffOn /> <includes> <include>**/*.yaml</include> <include>**/*.yml</include> </includes> <excludes> <exclude>**/target/**/*.yaml</exclude> <exclude>**/target/**/*.yml</exclude> </excludes> <prettier> <config> <singleQuote>false</singleQuote> </config> </prettier> </yaml> </configuration> </plugin> </plugins> </build> </profile> The Enforcer plugin provides goals to control certain environmental constraints such as Maven version, JDK version and OS family along with many more built-in rules and user created rules.The https://maven.apache.org/enforcer/enforcer-rules/dependencyConvergence.html#dependency-convergence dependencyConvergence rule requires that dependency version numbers converge. If a project has two dependencies, A and B, both depending on the same artifact, C, this rule will fail the build if A depends on a different version of C than the version of C depended on by B.The https://maven.apache.org/enforcer/enforcer-rules/requirePluginVersions.html requirePluginVersions rule enforces that all plugins have a version defined, either in the plugin or pluginManagement section of the pom or a parent pom.The https://maven.apache.org/enforcer/enforcer-rules/bannedDependencies.html bannedDependencies rule is configured to ban all loggers except Log4j 1.x and Logback.The https://maven.apache.org/enforcer/enforcer-rules/banDuplicatePomDependencyVersions.html banDuplicatePomDependencyVersions checks that there are no duplicate dependencies declared in the POM of the project. Duplicate dependencies are dependencies which have the same group id, artifact id, type and classifier. extra-enforcer-rules The https://www.mojohaus.org/extra-enforcer-rules/ extra-enforcer-rules project provides extra rules which are not part of the standard rule set. The liftwizard-minimal-parent configures maven-enforcer-plugin to use the extra-enforcer-rules . <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-enforcer-plugin</artifactId> <version>3.5.0</version> <dependencies> <dependency> <groupId>org.codehaus.mojo</groupId> <artifactId>extra-enforcer-rules</artifactId> <version>1.8.0</version> </dependency> </dependencies> </plugin>"],["temporal-data@@temporal-data-overview@@temporal-features","Temporal Data","Temporal Data Overview","Temporal features","Liftwizard has built-in support for working with temporal data. In this section, we'll explore the various features of services that utilize this technology.Note: This section is language and framework agnostic. If youâ€™re interested in the underlying technology, Liftwizard's temporal support is built on reladomo/reladomo-overview.md Reladomo.In an application with temporal data storage, data is stored along with timestamps. Here are some key features of temporal support: temporal-data/non-destructive-updates Non-destructive edits: Updates and deletes won't lose any information. Old data is phased out with a timestamp, and new data is phased in at the same timestamp. temporal-data/as-of-queries As-of queries: Retrieve data as it existed at a specific point in time. temporal-data/versioning Versioning: Numbered versions of data can make working with timestamps easier. As-of queries can be performed by either timestamp or version number. temporal-data/auditing Auditing: Keep track of who made each change, along with the data. With auditing enabled, each version has a user ID in addition to its timestamps. temporal-data/optimistic-locking Optimistic locking: Prevent multiple users from accidentally discarding each other's work with this feature. APIs that perform edits require a version number as input, and will fail if the input version number and current version number don't match. temporal-data/diffs Diff: See the differences between data at two version numbers. temporal-data/maker-checker-workflows Maker/Checker workflows: Make and review changes before exposing them to all users. Most users view the latest approved version of the data, while makers/checkers see the latest version.In the next section, we'll walk through a temporal-data/running-example running example that showcases these features."],["temporal-data@@running-example@@","Temporal Data","Running Example","","Many real-life applications support temporal services. https://stackoverflow.com/ Stack Overflow supports all of the features listed in the temporal-data/temporal-data-overview overview.In this section, we'll use https://www.factorio.school/blueprints Factorio School as a running example. https://www.factorio.school/ Factorio School and https://factorioprints.com/ Factorio Prints are websites that lets users share designs, called https://wiki.factorio.com/Blueprint blueprints, for the video game https://factorio.com/ Factorio. Liftwizard and Factorio School were both created by the https://github.com/motlin/ same author and Factorio School leverages Liftwizard's temporal support.In the next section, we'll create and edit a blueprint, and see how non-destructive edits work."],["temporal-data@@non-destructive-updates@@post-request-body","Temporal Data","Non Destructive Updates","POST Request Body","Blueprints are created in 3 steps, starting with a test clock set at 2001-01-01 .At time 1 ( 2001-01-01 ), we create an Imgur Image entry. At time 2 ( 2001-01-02 ), we upload the blueprint string and receive a sha. At time 3 ( 2001-01-03 ), we upload the blueprint post. In this documentation, we'll focus on the third step.We create a blueprint post by POST ing to /api/blueprint/ . { title: \"Blueprint title\", blueprintString: { // The blueprintString.sha is a foreign key, pointing to the blueprint data we created at time 2. sha: \"cc341849b4086ce7b1893b366b0dc8e99ce4e595\", }, imgurImage: { // The imgurImage.imgurId is a foreign key, pointing to the Imgur Image data we created at time 1. imgurId: \"Imgur ID 1\", }, descriptionMarkdown: \"Blueprint description markdown\", // Blueprints can be tagged with multiple tags. Here we have a single tag, \"belt balancer\". tags: [ { // This double nesting is how many-to-many relationships are represented. This object is the BlueprintTag mapping. tag: { // This object is the tag. It's part of reference data that was created earlier. The (category, name) pair is the foreign key. category: \"belt\", name: \"balancer\", }, }, ], }"],["temporal-data@@non-destructive-updates@@post-response-body","Temporal Data","Non Destructive Updates","POST Response Body","The response includes all the properties we sent, along with server-generated information. { \"key\": \"6ed1f638-a63c-3a54-af67-ba494f27bff2\", \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null, \"version\": { \"number\": 1, \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null, \"createdOn\": \"2001-01-03T23:59:59Z\", \"createdBy\": { \"userId\": \"User ID\" }, \"lastUpdatedBy\": { \"userId\": \"User ID\" } }, \"title\": \"Blueprint title\", \"voteSummary\": { \"numberOfUpvotes\": 0, \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null }, \"blueprintString\": { \"sha\": \"cc341849b4086ce7b1893b366b0dc8e99ce4e595\", \"createdOn\": \"2001-01-02T23:59:59Z\", \"createdBy\": { \"userId\": \"User ID\" } }, \"imgurImage\": { \"imgurId\": \"Imgur ID 1\", \"imgurType\": \"image/png\", \"height\": 300, \"width\": 300, \"systemFrom\": \"2001-01-01T23:59:59Z\", \"systemTo\": null }, \"descriptionMarkdown\": \"Blueprint description markdown\", \"tags\": [ { \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null, \"tag\": { \"category\": \"belt\", \"name\": \"balancer\", \"ordinal\": 1, \"systemFrom\": \"2000-01-01T00:00:00Z\", \"systemTo\": null } } ] }"],["temporal-data@@non-destructive-updates@@temporal-response","Temporal Data","Non Destructive Updates","Temporal Response","Here's the same response, with some temporal features labeled. These will be covered in upcoming sections. { // The key is generated-server side. key: \"6ed1f638-a63c-3a54-af67-ba494f27bff2\", // The systemFrom is the time we created the blueprint post time 3: 2001-01-03. systemFrom: \"2001-01-03T23:59:59Z\", // The systemTo is null, or infinity, indicating this data is current. systemTo: null, // The version object is covered in the section on Versioning. version: { number: 1, systemFrom: \"2001-01-03T23:59:59Z\", systemTo: null, // The createdOn, createdBy, and lastUpdatedBy properties are covered in the section on Auditing. createdOn: \"2001-01-03T23:59:59Z\", createdBy: { userId: \"User ID\", }, lastUpdatedBy: { userId: \"User ID\", }, }, title: \"Blueprint title\", voteSummary: { numberOfUpvotes: 0, systemFrom: \"2001-01-03T23:59:59Z\", systemTo: null, }, blueprintString: { // The request only included blueprintString.sha, a foreign key. The response includes the whole object. sha: \"cc341849b4086ce7b1893b366b0dc8e99ce4e595\", // We created the blueprint data at time 2: 2001-01-02. createdOn: \"2001-01-02T23:59:59Z\", createdBy: { userId: \"User ID\", }, }, imgurImage: { // The request only included the imgurImage.id, a foreign key. The response includes the whole object. imgurId: \"Imgur ID 1\", imgurType: \"image/png\", height: 300, width: 300, // We created the Imugr image at time 1: 2001-01-01. systemFrom: \"2001-01-01T23:59:59Z\", systemTo: null, }, descriptionMarkdown: \"Blueprint description markdown\", tags: [ { // The BlueprintTag mapping was created along with the blueprint post at time 3: 2001-01-03. systemFrom: \"2001-01-03T23:59:59Z\", systemTo: null, tag: { // The request only included tag.category and tag.name, the composite foreign key. The response includes the whole object. category: \"belt\", name: \"balancer\", ordinal: 1, // It was created a year earlier than the Blueprint. systemFrom: \"2000-01-01T00:00:00Z\", systemTo: null, }, }, ], }"],["temporal-data@@non-destructive-updates@@non-destructive-updates","Temporal Data","Non Destructive Updates","Non-destructive updates","Next, we update the blueprint by PATCH ing /api/blueprint/{id}?version=1 ."],["temporal-data@@non-destructive-updates@@response","Temporal Data","Non Destructive Updates","Response","The response includes the updated properties we sent, plus our first temporal updates.The edits are reflected at time 4 ( 2001-01-04 ). { \"key\": \"6ed1f638-a63c-3a54-af67-ba494f27bff2\", - \"systemFrom\": \"2001-01-03T23:59:59Z\", + \"systemFrom\": \"2001-01-04T23:59:59Z\", \"systemTo\": null, \"version\": { - \"number\": 1, - \"systemFrom\": \"2001-01-03T23:59:59Z\", + \"number\": 2, + \"systemFrom\": \"2001-01-04T23:59:59Z\", \"systemTo\": null, \"createdOn\": \"2001-01-03T23:59:59Z\", \"createdBy\": { \"userId\": \"User ID\" }, \"lastUpdatedBy\": { \"userId\": \"User ID\" } }, - \"title\": \"Blueprint title\", + \"title\": \"Edited blueprint title\", \"voteSummary\": { \"numberOfUpvotes\": 0, \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null }, \"blueprintString\": { \"sha\": \"cc341849b4086ce7b1893b366b0dc8e99ce4e595\", \"createdOn\": \"2001-01-02T23:59:59Z\", \"createdBy\": { \"userId\": \"User ID\" } }, \"imgurImage\": { \"imgurId\": \"Imgur ID 1\", \"imgurType\": \"image/png\", \"height\": 300, \"width\": 300, \"systemFrom\": \"2001-01-01T23:59:59Z\", \"systemTo\": null }, - \"descriptionMarkdown\": \"Blueprint description markdown\", + \"descriptionMarkdown\": \"Edited Blueprint description markdown\", \"tags\": [ { \"tagCategory\": \"belt\", \"tagName\": \"balancer\", \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null, \"tag\": { \"category\": \"belt\", \"name\": \"balancer\", \"ordinal\": 1, \"systemFrom\": \"2000-01-01T00:00:00Z\", \"systemTo\": null } } ] }"],["temporal-data@@non-destructive-updates@@as-of-query","Temporal Data","Non Destructive Updates","As-of query","In the next section, we'll perform our first as-of query to prove to ourselves that no data has been lost."],["temporal-data@@as-of-queries@@temporal-schema","Temporal Data","As Of Queries","Temporal Schema","To confirm that we have not lost any data, we can perform an as-of query. We want to query the state of the blueprint at time 3 ( 2001-01-03 ), before the non-destructive update.We GET from /api/blueprint/{blueprintKey}?asOf={asOf} .We created a blueprint with key 6ed1f638-a63c-3a54-af67-ba494f27bff2 at time 3 ( 2001-01-03 ) and edited it at time 4 ( 2001-01-04 ). We can query as-of any time in the range [2001-01-03, 2001-01-04) . We'll use the beginning of the range: 2001-01-03 .Plugging these values into the template, we GET /api/blueprint/6ed1f638-a63c-3a54-af67-ba494f27bff2?asOf=2001-01-03T23:59:59Z { \"key\": \"6ed1f638-a63c-3a54-af67-ba494f27bff2\", \"systemFrom\": \"2001-01-03T23:59:59Z\", - \"systemTo\": null, + \"systemTo\": \"2001-01-04T23:59:59Z\", \"version\": { \"number\": 1, \"systemFrom\": \"2001-01-03T23:59:59Z\", - \"systemTo\": null, + \"systemTo\": \"2001-01-04T23:59:59Z\", \"createdOn\": \"2001-01-03T23:59:59Z\", \"createdBy\": { \"userId\": \"User ID\" }, \"lastUpdatedBy\": { \"userId\": \"User ID\" } }, \"title\": \"Blueprint title\", \"voteSummary\": { \"numberOfUpvotes\": 0, \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null }, \"blueprintString\": { \"sha\": \"cc341849b4086ce7b1893b366b0dc8e99ce4e595\", \"createdOn\": \"2001-01-02T23:59:59Z\", \"createdBy\": { \"userId\": \"User ID\" } }, \"imgurImage\": { \"imgurId\": \"Imgur ID 1\", \"imgurType\": \"image/png\", \"height\": 300, \"width\": 300, \"systemFrom\": \"2001-01-01T23:59:59Z\", \"systemTo\": null }, \"descriptionMarkdown\": \"Blueprint description markdown\", \"tags\": [ { \"tagCategory\": \"belt\", \"tagName\": \"balancer\", \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null, \"tag\": { \"category\": \"belt\", \"name\": \"balancer\", \"ordinal\": 1, \"systemFrom\": \"2000-01-01T00:00:00Z\", \"systemTo\": null } } ] } The response we get from /api/blueprint/{blueprintKey}?asOf=2001-01-03T23:59:59Z is nearly identical to the response we would have got from /api/blueprint/{blueprintKey} had we run the query at time 3: 2001-01-03 . This makes sense!There's a small difference in the data. Some of the systemTo values that used to be null are now time 4: 2001-01-04 . This illustrates an important rule of temporal data.All writes into the data store are immutable and append-only, except for the systemTo value.Next we'll focus on the data store. In this example, we're using a relational database, but these concepts apply to any data store.The schema maps closely to the json examples above, so if you're comfortable with the data, feel free to skip ahead to the queries. BLUEPRINT after create systemFrom systemTo key blueprint title descriptionMarkdown imgurImageId blueprintStringSha 2001-01-03 23:59:59.0 9999-12-01 23:59:00.0 6ed1â€¦ Blueprint title Blueprint description markdown Imgur ID 1 cc34â€¦ BLUEPRINT after update systemFrom systemTo key blueprint title descriptionMarkdown imgurImageId blueprintStringSha `:icon: minus {stroke: 'red'}` 2001-01-03 23:59:59.0 `:icon: plus {stroke: 'green'}` 2001-01-04 23:59:59.0 6ed1â€¦ `:icon: minus {stroke: 'red'}` Blueprint title `:icon: minus {stroke: 'red'}` Blueprint description markdown Imgur ID 1 cc34â€¦ `:icon: plus {stroke: 'green'}` 2001-01-04 23:59:59.0 9999-12-01 23:59:00.0 6ed1â€¦ `:icon: plus {stroke: 'green'}` Edited blueprint title `:icon: plus {stroke: 'green'}` Edited Blueprint description markdown Imgur ID 1 cc34â€¦ BLUEPRINT_VERSION after create systemFrom systemTo key createdById lastUpdatedById number createdOn 2001-01-03 23:59:59.0 9999-12-01 23:59:00.0 6ed1â€¦ User ID User ID 1 2001-01-03 23:59:59.0 BLUEPRINT_VERSION after update systemFrom systemTo key createdById lastUpdatedById number createdOn `:icon: minus {stroke: 'red'}` 2001-01-03 23:59:59.0 `:icon: plus {stroke: 'green'}` 2001-01-04 23:59:59.0 6ed1â€¦ User ID User ID `:icon: minus {stroke: 'red'}` 1 2001-01-03 23:59:59.0 `:icon: plus {stroke: 'green'}` 2001-01-04 23:59:59.0 9999-12-01 23:59:00.0 6ed1â€¦ User ID User ID `:icon: plus {stroke: 'green'}` 2 2001-01-03 23:59:59.0 Temporal Schema patterns All tables have systemFrom and systemTo columns. Old data is phased out by setting systemTo to now. New data is phased in by setting systemFrom to now. The new row's systemFrom and the old row's systemTo are set to the same value, forming a contiguous timeline. When several tables are edited within a transaction, the systemFrom and systemTo values are set to the same value across all tables. Unchanged data is copied from the old row to the new row. For very wide columns that don't change frequently, it may be more efficient to split out a separate table. The systemTo value of the new row is set to 9999-12-01 23:59:00.00 to indicate that the row is still active. In json, we had used null to represent the infinity date."],["temporal-data@@as-of-queries@@temporal-queries-in-sql","Temporal Data","As Of Queries","Temporal queries in SQL","As-of queries are implemented in SQL by adding temporal criteria to our WHERE clause. sql select * from BLUEPRINT t0 where t0.key = '6ed1f638-a63c-3a54-af67-ba494f27bff2' and t0.system_from <= '2001-01-03 23:59:59.000' and t0.system_to > '2001-01-03 23:59:59.000' Now we can see why the infinity date is represented as 9999-12-01 23:59:00.00 . If we instead used null we'd need to add additional criteria to our WHERE clauses.Joins that are one hop away from our main table are similar. sql select * from BLUEPRINT_TAG t0 where t0.blueprint_key = '6ed1f638-a63c-3a54-af67-ba494f27bff2' and t0.system_from <= '2001-01-03 23:59:59.000' and t0.system_to > '2001-01-03 23:59:59.000' Joins that are two hops away from our main table are more complicated. We'll see examples of these later. Temporal query patterns We perform asOf queries by adding where system_from <= {asOf} and system_to > {asOf} to our WHERE clause. We add this exact came criteria to every query. We always SELECT all columns from the table. In the examples above we used SELECT * . In production usage, it's common to list the columns explicitly. We never SELECT columns from two tables in the same query. Even in the upcoming examples of joins, we always SELECT from one table at a time. In the next section, we'll learn about adding versions and querying \"as of\" a version number."],["temporal-data@@versioning@@query-as-of-version","Temporal Data","Versioning","Query as-of version","We've already seen version numbers in some examples. When we edited our Blueprint, the version number increased from 1 to 2.When querying for previous data, version numbers can be more convenient than timestamps. We'll see this in the section on querying by version.With versioning, we bump the version number when we edit any data within the composite. For Blueprints, this means that we bump the version number when we edit the Blueprint itself, when we replace the ImgurImage, when we replace the blueprint string, and when we add or remove tags. We'll take a closer look in the section on Composites.As-of queries by version over rest are performed by adding a version query parameter to the URL.Our template is GET /api/blueprint/{blueprintKey}?version={version} .Plugging in the key from our running example, and the version number 1, we GET /api/blueprint/6ed1f638-a63c-3a54-af67-ba494f27bff2?version=1 This is similar to the as-of query by timestamp from the previous section, and the response is identical so we won't repeat it here."],["temporal-data@@versioning@@version-queries-in-sql","Temporal Data","Versioning","Version queries in SQL","At the SQL layer, queries by version number are implemented by starting with the version table. sql select * from BLUEPRINT_VERSION t0 where t0.key = '6ed1f638-a63c-3a54-af67-ba494f27bff2' and t0.number = 1 This query returns version 1, which existed for the duration [2001-01-03, 2001-01-04) . systemFrom systemTo key createdById lastUpdatedById number createdOn 2001-01-03 23:59:59.0 2001-01-04 23:59:59.0 6ed1â€¦ User ID User ID 1 2001-01-03 23:59:59.0 2001-01-04 23:59:59.0 9999-12-01 23:59:00.0 6ed1â€¦ User ID User ID 2 2001-01-03 23:59:59.0 At this point we take the system_from value of 2001-01-03 23:59:59.000 and use it in our subsequent queries. The queries on all other tables are identical to the queries in the previous section.For example, to query the BLUEPRINT table: sql select * from BLUEPRINT t0 where t0.key = '6ed1f638-a63c-3a54-af67-ba494f27bff2' and t0.system_from <= '2001-01-03 23:59:59.000' and t0.system_to > '2001-01-03 23:59:59.000'"],["temporal-data@@versioning@@composites","Temporal Data","Versioning","Composites","In the previous example, we edited the Blueprint's title and markdown description, creating version 2.Now we'll replace the Blueprint string, the ImgurImage, and add two more tags. We want to bump the version number just once more, to 3.We update the blueprint by PATCH ing /api/blueprint/{id}?version=2 ."],["temporal-data@@versioning@@response","Temporal Data","Versioning","Response","As desired, we performed the several edits while bumping the version number by only one.In addition, all of the new systemFrom times are identical: 2001-01-05T23:59:59Z .At the SQL level, all the edits were performed in a single transaction. { \"key\": \"6ed1f638-a63c-3a54-af67-ba494f27bff2\", - \"systemFrom\": \"2001-01-04T23:59:59Z\", + \"systemFrom\": \"2001-01-05T23:59:59Z\", \"systemTo\": null, \"version\": { - \"number\": 2, - \"systemFrom\": \"2001-01-04T23:59:59Z\", + \"number\": 3, + \"systemFrom\": \"2001-01-05T23:59:59Z\", \"systemTo\": null, \"createdOn\": \"2001-01-03T23:59:59Z\", \"createdBy\": { \"userId\": \"User ID\" }, \"lastUpdatedBy\": { \"userId\": \"User ID\" } }, \"title\": \"Edited blueprint title\", \"voteSummary\": { \"numberOfUpvotes\": 0, \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null }, \"blueprintString\": { - \"sha\": \"cc341849b4086ce7b1893b366b0dc8e99ce4e595\", - \"createdOn\": \"2001-01-02T23:59:59Z\", + \"sha\": \"b11911083a0cf471a5156108389f9899675ccb0c\", + \"createdOn\": \"2001-01-03T00:00:00Z\", \"createdBy\": { \"userId\": \"User ID\" } }, \"imgurImage\": { - \"imgurId\": \"Imgur ID 1\", - \"imgurType\": \"image/png\", - \"height\": 300, - \"width\": 300, + \"imgurId\": \"2nd Imgur ID\", + \"imgurType\": \"2nd Imgur Type\", + \"height\": 200, + \"width\": 200, \"systemFrom\": \"2001-01-01T23:59:59Z\", \"systemTo\": null }, \"descriptionMarkdown\": \"Edited Blueprint description markdown\", \"tags\": [ { \"tagCategory\": \"belt\", \"tagName\": \"balancer\", \"systemFrom\": \"2001-01-03T23:59:59Z\", \"systemTo\": null, \"tag\": { \"category\": \"belt\", \"name\": \"balancer\", \"ordinal\": 1, \"systemFrom\": \"2000-01-01T00:00:00Z\", \"systemTo\": null } + }, + { + \"tagCategory\": \"belt\", + \"tagName\": \"prioritizer\", + \"systemFrom\": \"2001-01-05T23:59:59Z\", + \"systemTo\": null, + \"tag\": { + \"category\": \"belt\", + \"name\": \"prioritizer\", + \"ordinal\": 2, + \"systemFrom\": \"2000-01-01T00:00:00Z\", + \"systemTo\": null + } + }, + { + \"tagCategory\": \"moderation\", + \"tagName\": \"scheduled for deletion\", + \"systemFrom\": \"2001-01-05T23:59:59Z\", + \"systemTo\": null, + \"tag\": { + \"category\": \"moderation\", + \"name\": \"scheduled for deletion\", + \"ordinal\": 18, + \"systemFrom\": \"2000-01-01T00:00:00Z\", + \"systemTo\": null + } } ] }"],["temporal-data@@versioning@@ownership-direction","Temporal Data","Versioning","Ownership direction","BlueprintTag sits in the middle of a many-to-many relationship between Blueprint and Tag . In this example, we considered BlueprintTag to be part of the composite making up the Blueprint . Should we also consider it to be part of the Tag as well?This is our choice as application designers. In this case, it makes sense for BlueprintTag to be part of the Blueprint , but not part of Tag .Stack Overflow makes a similar choice. Questions and Tag s are both versioned. Applying new tags to a question creates a new version of the Question , but not the Tag .In the UML diagram above, composite relationships are denoted by black diamonds.Composites are subtle, so let's walk through a few examples.Editing a Blueprint's title or description creates a new version. These are properties directly on the root type. Adding or removing BlueprintTag mappings creates a new version. These objects live within the composite. BlueprintTag mappings don't have any mutable properties. If they did, editing those properties would create a new version. For example, if we persisted their relative ordering with an ordinal property, then reordering the Blueprint's tags would create a new version. When the Blueprint author changes their display name, this does not create a new version. The User object is not part of the composite. We don't allow reassigning Blueprints to another author. If we did, repointing the author would create a new version. This works well with a temporal schema, because Blueprint.createdById would be swapped."],["temporal-data@@auditing@@","Temporal Data","Auditing","","Auditing means tracking who performed each create and update operation.The version object is a convenient place to store this information. Each version has a createdOn timestamp, and createdBy and lastUpdatedBy fields.The version table includes column createdById and lastUpdatedById that point to a user table. Deletes"]]
/*
 * Copyright 2019 TWO SIGMA OPEN SOURCE, LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

znaiSearchIdx = lunr(function () {
    this.ref('id')
    this.field('section')
    this.field('pageTitle')
    this.field('pageSection')
    this.field('text')

    this.metadataWhitelist = ['position']

    znaiSearchData.forEach(function (e) {
        this.add({
            id: e[0],
            section: e[1],
            pageTitle: e[2],
            pageSection: e[3],
            text: e[4],
        })
    }, this)
})
